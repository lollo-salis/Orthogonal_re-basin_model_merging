{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egEs8NDkmudC"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ut3sT8Njlldg",
        "outputId": "7d916adc-f7da-48e6-e94f-0afc8accb874"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from copy import deepcopy\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import sys\n",
        "import os\n",
        "\n",
        "module_path = os.path.abspath(os.path.join('..'))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from src.models import MLP, MLP_CIFAR\n",
        "from src.aligners import PermutationAligner, OrthogonalAligner\n",
        "from src.utils import get_datasets, train_model, evaluate_model, evaluate_interpolation, slerp_evaluate_interpolation, compare_predictions, calculate_logit_distance\n",
        "\n",
        "# --- Configuration ---\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {DEVICE}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBq2nnIJnr5F"
      },
      "source": [
        "# Experiment MNIST"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LCuv0955nuSi"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXlx2xsInrlU",
        "outputId": "127d60e5-6fe4-422d-ab40-d373f1c2fcde"
      },
      "outputs": [],
      "source": [
        "# Setup\n",
        "DATASET_NAME = 'MNIST'\n",
        "MODEL_ARCH = MLP\n",
        "EPOCHS = 3\n",
        "BATCH_SIZE = 128\n",
        "SEED_A = 42\n",
        "SEED_B = 123\n",
        "\n",
        "# 1. Load dataset\n",
        "print(f\"--- Loading dataset {DATASET_NAME} ---\")\n",
        "train_dataset, test_dataset, _ = get_datasets(DATASET_NAME)\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 2. Training Model A\n",
        "print(f\"\\n--- Training Model A (seed={SEED_A}) ---\")\n",
        "torch.manual_seed(SEED_A)\n",
        "model_a = MODEL_ARCH()\n",
        "train_model(model_a, train_loader, DEVICE, EPOCHS)\n",
        "sd_a = model_a.state_dict()\n",
        "loss_a, acc_a = evaluate_model(model_a, test_loader, DEVICE)\n",
        "print(f\"Model A - Test Loss: {loss_a:.4f}, Test Accuracy: {acc_a:.2f}%\")\n",
        "\n",
        "# 3. Training Model B\n",
        "print(f\"\\n--- Training Model B (seed={SEED_B}) ---\")\n",
        "torch.manual_seed(SEED_B)\n",
        "model_b = MODEL_ARCH()\n",
        "train_model(model_b, train_loader, DEVICE, epochs=EPOCHS)\n",
        "sd_b = model_b.state_dict()\n",
        "loss_b, acc_b = evaluate_model(model_b, test_loader, DEVICE)\n",
        "print(f\"Model B - Test Loss: {loss_b:.4f}, Test Accuracy: {acc_b:.2f}%\")\n",
        "\n",
        "print(\"\\n--- Models A and B succesfully trained ---\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeF_lL3BpgVM"
      },
      "source": [
        "## Alignments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OH7tf_rMpfZV",
        "outputId": "7558a2fb-1467-4e31-9632-14d40222d4b2"
      },
      "outputs": [],
      "source": [
        "# --- Esecuzione dell'Allineamento ---\n",
        "print(\"\\n--- Executing the alignments ---\")\n",
        "\n",
        "# 1. Allineamento con Permutazioni\n",
        "permutation_aligner = PermutationAligner(MODEL_ARCH)\n",
        "aligned_sd_b_perm = permutation_aligner.align(sd_a, sd_b)\n",
        "\n",
        "# 2. Allineamento Ortogonale\n",
        "orthogonal_aligner = OrthogonalAligner(MODEL_ARCH)\n",
        "aligned_sd_b_orth = orthogonal_aligner.align(sd_a, sd_b)\n",
        "\n",
        "print(\"\\n--- Alignments completed ---\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sdrarYG1mea",
        "outputId": "a7eee0d5-cfb1-4f08-bd4f-b92d59dd1e07"
      },
      "outputs": [],
      "source": [
        "# --- Quantificazione dell'Errore di Disallineamento Residuo ---\n",
        "\n",
        "print(\"\\n--- Quantifying residual misalignment error ---\")\n",
        "\n",
        "# Creiamo istanze temporanee dei modelli per caricare gli state_dict allineati\n",
        "aligned_model_perm = MODEL_ARCH().to(DEVICE)\n",
        "aligned_model_perm.load_state_dict(aligned_sd_b_perm)\n",
        "\n",
        "aligned_model_orth = MODEL_ARCH().to(DEVICE)\n",
        "aligned_model_orth.load_state_dict(aligned_sd_b_orth)\n",
        "\n",
        "# Recuperiamo l'accuratezza del model_b originale per riferimento\n",
        "_, acc_b_original = evaluate_model(model_b, test_loader, DEVICE)\n",
        "\n",
        "# Calcoliamo le metriche per l'allineamento a permutazione\n",
        "_, acc_perm = evaluate_model(aligned_model_perm, test_loader, DEVICE)\n",
        "agreement_perm = compare_predictions(model_b, aligned_model_perm, test_loader, DEVICE)\n",
        "mse_perm = calculate_logit_distance(model_b, aligned_model_perm, test_loader, DEVICE)\n",
        "\n",
        "# Calcoliamo le metriche per l'allineamento ortogonale\n",
        "_, acc_orth = evaluate_model(aligned_model_orth, test_loader, DEVICE)\n",
        "agreement_orth = compare_predictions(model_b, aligned_model_orth, test_loader, DEVICE)\n",
        "mse_orth = calculate_logit_distance(model_b, aligned_model_orth, test_loader, DEVICE)\n",
        "\n",
        "\n",
        "# --- Functional Comparison After Alignment (vs. Original Model B) ---\n",
        "print(\"\\nFunctional Comparison After Alignment (vs. Original Model B)\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Alignment Method':<25} | {'Accuracy':>15} | {'Prediction Agreement':>20} | {'Logits MSE':>12}\")\n",
        "print(\"-\" * 80)\n",
        "print(f\"{'Original (Model B)':<25} | {acc_b_original:>14.2f}% | {'100.00%':>19} | {'0.0':>12}\")\n",
        "print(f\"{'Permutation':<25} | {acc_perm:>14.2f}% | {agreement_perm:>19.2f}% | {mse_perm:>12.6f}\")\n",
        "print(f\"{'Orthogonal (Procrustes)':<25} | {acc_orth:>14.2f}% | {agreement_orth:>19.2f}% | {mse_orth:>12.4f}\")\n",
        "print(\"-\" * 80)\n",
        "\n",
        "print(\"\\nAnalysis:\")\n",
        "print(\"Permutation alignment almost perfectly preserves the model's function (MSE is near zero, agreement ~100%).\")\n",
        "print(\"Orthogonal alignment introduces a significant residual misalignment error,\")\n",
        "print(\"as shown by the drop in accuracy and the high MSE value. This is due to its non-commutativity with the ReLU activation function.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A0YuSZSnsI3G"
      },
      "source": [
        "# Graphs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "2sB4TRdDsKvB",
        "outputId": "92656786-126e-42e8-a660-2a0d3770214c"
      },
      "outputs": [],
      "source": [
        "# 2. Esecuzione delle interpolazioni\n",
        "print(\"\\n--- Executing interpolations ---\")\n",
        "\n",
        "# a) Non allineato (Naive LERP)\n",
        "print(\"\\n1. Naive Interpolation:\")\n",
        "alphas, losses_naive, accs_naive = evaluate_interpolation(MODEL_ARCH, sd_a, sd_b, test_loader, DEVICE)\n",
        "\n",
        "# b) Allineato con Permutazioni (Git Re-Basin LERP)\n",
        "print(\"\\n2. LERP interpolation between PERMUTATION aligned models:\")\n",
        "alphas, losses_perm, accs_perm = evaluate_interpolation(MODEL_ARCH, sd_a, aligned_sd_b_perm, test_loader, DEVICE)\n",
        "\n",
        "# c) Allineato Ortogonalmente (Procrustes LERP)\n",
        "print(\"\\n3. LERP interpolation between ORTHOGONAL aligned models:\")\n",
        "alphas, losses_orth, accs_orth = evaluate_interpolation(MODEL_ARCH, sd_a, aligned_sd_b_orth, test_loader, DEVICE)\n",
        "\n",
        "# d) Allineato con Permutazioni (Git Re-Basin SLERP)\n",
        "print(\"\\n4. SLERP interpolation between PERMUTATION aligned models:\")\n",
        "alphas, losses_slerp, accs_slerp = slerp_evaluate_interpolation(MODEL_ARCH, sd_a, aligned_sd_b_perm, test_loader, DEVICE)\n",
        "\n",
        "\n",
        "# 3. Generazione dei grafici finali\n",
        "print(\"\\n--- Generating graphs ---\")\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "# Grafico della Loss\n",
        "ax1.plot(alphas, losses_naive, marker='o', linestyle='--', label='Unaligned (LERP)')\n",
        "ax1.plot(alphas, losses_perm, marker='s', linestyle='-', label='Permutation-Aligned (LERP)')\n",
        "ax1.plot(alphas, losses_orth, marker='x', linestyle=':', label='Orthogonal-Aligned (LERP)')\n",
        "ax1.plot(alphas, losses_slerp, marker='d', linestyle='-.', label='Permutation-Aligned (SLERP)')\n",
        "ax1.set_title('Test Loss during Weight Space Interpolation')\n",
        "ax1.set_xlabel('Interpolation Coefficient (α) [Model A to B]')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.grid(True)\n",
        "ax1.legend()\n",
        "\n",
        "# Grafico dell'Accuratezza\n",
        "ax2.plot(alphas, accs_naive, marker='o', linestyle='--', label='Unaligned (LERP)')\n",
        "ax2.plot(alphas, accs_perm, marker='s', linestyle='-', label='Permutation-Aligned (LERP)')\n",
        "ax2.plot(alphas, accs_orth, marker='x', linestyle=':', label='Orthogonal-Aligned (LERP)')\n",
        "ax2.plot(alphas, accs_slerp, marker='d', linestyle='-.', label='Permutation-Aligned (SLERP)')\n",
        "ax2.set_title('Test Accuracy during Weight Space Interpolation')\n",
        "ax2.set_xlabel('Interpolation Coefficient (α) [Model A to B]')\n",
        "ax2.set_ylabel('Test Accuracy (%)')\n",
        "ax2.grid(True)\n",
        "# Imposta un limite inferiore per l'accuratezza per una migliore visualizzazione\n",
        "min_acc = min(np.min(accs_naive), np.min(accs_orth), np.min(accs_perm), np.min(accs_slerp)) if len(accs_naive) > 0 else 10\n",
        "ax2.set_ylim(bottom=max(0, min_acc - 10), top=100)\n",
        "\n",
        "\n",
        "plt.suptitle('Comparison of Alignment and Interpolation Methods for MLP on MNIST', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-pnhnlGn1255",
        "outputId": "f9faa02a-6faa-43b5-9d97-a2b2f4cfb10b"
      },
      "outputs": [],
      "source": [
        "# --- Test di Coerenza Ciclica (Cycle-Consistency) ---\n",
        "\n",
        "print(\"\\n--- Cycle-Consistency test ---\")\n",
        "\n",
        "# --- Test per OrthogonalAligner ---\n",
        "orth_aligner_test = OrthogonalAligner(MODEL_ARCH)\n",
        "# Calcola la trasformazione da A a B (allinea B a A)\n",
        "_, Q_ab = orth_aligner_test.align(sd_a, sd_b, return_transformations=True)\n",
        "# Calcola la trasformazione da B a A (allinea A a B)\n",
        "_, Q_ba = orth_aligner_test.align(sd_b, sd_a, return_transformations=True)\n",
        "\n",
        "# Verifichiamo per il primo layer\n",
        "Q1_ab = Q_ab['layer1']\n",
        "Q1_ba = Q_ba['layer1']\n",
        "identity = torch.eye(Q1_ab.shape[0], device=DEVICE)\n",
        "product = torch.matmul(Q1_ab, Q1_ba)\n",
        "is_consistent_orth = torch.allclose(product, identity, atol=1e-5)\n",
        "print(f\" Is OrthogonalAligner cycle-consistent? {is_consistent_orth}\")\n",
        "print(f\"  Nrom of ||Q_ab @ Q_ba - I||: {torch.norm(product - identity).item():.6f}\")\n",
        "\n",
        "# --- Test per PermutationAligner ---\n",
        "perm_aligner_test = PermutationAligner(MODEL_ARCH)\n",
        "# Calcola la permutazione da A a B\n",
        "_, P_ab_indices = perm_aligner_test.align(sd_a, sd_b, return_transformations=True)\n",
        "# Calcola la permutazione da B a A\n",
        "_, P_ba_indices = perm_aligner_test.align(sd_b, sd_a, return_transformations=True)\n",
        "\n",
        "# Costruiamo le matrici di permutazione dal primo layer\n",
        "P1_ab_idx = P_ab_indices['layer1']\n",
        "P1_ba_idx = P_ba_indices['layer1']\n",
        "size = len(P1_ab_idx)\n",
        "\n",
        "# Verifichiamo la coerenza degli indici: P_ba(P_ab(i)) == i\n",
        "reordered_indices = P1_ba_idx[P1_ab_idx]\n",
        "is_consistent_perm_indices = torch.equal(reordered_indices, torch.arange(size, device=DEVICE))\n",
        "print(f\"Is PermutationAligner cycle-consistent? {is_consistent_perm_indices}\")\n",
        "\n",
        "# Test opzionale con le matrici, che è equivalente\n",
        "P1_ab = torch.eye(size, device=DEVICE)[P1_ab_idx]\n",
        "P1_ba = torch.eye(size, device=DEVICE)[P1_ba_idx]\n",
        "product_perm = torch.matmul(P1_ab, P1_ba)\n",
        "is_consistent_perm_matrix = torch.allclose(product_perm, torch.eye(size, device=DEVICE))\n",
        "print(f\"  Matrix check: {is_consistent_perm_matrix}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tg5XrAmz2o0U"
      },
      "source": [
        "# Experiment CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ODqw6TOG2tLb",
        "outputId": "5556e34a-180d-4113-973c-0a489ccaf90d"
      },
      "outputs": [],
      "source": [
        "# --- ESPERIMENTO MLP su CIFAR-10 ---\n",
        "\n",
        "# Impostazioni Esperimento\n",
        "DATASET_NAME_MLP_CIFAR = 'CIFAR10'\n",
        "MODEL_ARCH_MLP_CIFAR = MLP_CIFAR \n",
        "EPOCHS_MLP_CIFAR = 20 \n",
        "BATCH_SIZE_MLP_CIFAR = 128\n",
        "SEED_A = 42\n",
        "SEED_B = 123\n",
        "\n",
        "# 1. Caricamento Dati\n",
        "print(f\"--- Loading dataset {DATASET_NAME_MLP_CIFAR} for MLP ---\")\n",
        "train_dataset_mc, test_dataset_mc, _ = get_datasets(DATASET_NAME_MLP_CIFAR)\n",
        "train_loader_mc = DataLoader(train_dataset_mc, batch_size=BATCH_SIZE_MLP_CIFAR, shuffle=True)\n",
        "test_loader_mc = DataLoader(test_dataset_mc, batch_size=BATCH_SIZE_MLP_CIFAR, shuffle=False)\n",
        "\n",
        "# 2. Addestramento di Model A (MLP su CIFAR10)\n",
        "print(f\"\\n--- Training Model A (MLP on CIFAR10, seed={SEED_A}) ---\")\n",
        "torch.manual_seed(SEED_A)\n",
        "model_a_mc = MODEL_ARCH_MLP_CIFAR().to(DEVICE)\n",
        "train_model(model_a_mc, train_loader_mc, DEVICE,  epochs=EPOCHS_MLP_CIFAR, weight_decay=1e-4) # Usiamo un po' di weight decay\n",
        "sd_a_mc = model_a_mc.state_dict()\n",
        "loss_a_mc, acc_a_mc = evaluate_model(model_a_mc, test_loader_mc, DEVICE)\n",
        "print(f\"Model A (MLP-CIFAR) - Test Loss: {loss_a_mc:.4f}, Test Accuracy: {acc_a_mc:.2f}%\")\n",
        "\n",
        "# 3. Addestramento di Model B (MLP su CIFAR10)\n",
        "print(f\"\\n--- Training Model B (MLP on CIFAR10, seed={SEED_B}) ---\")\n",
        "torch.manual_seed(SEED_B)\n",
        "model_b_mc = MODEL_ARCH_MLP_CIFAR().to(DEVICE)\n",
        "train_model(model_b_mc, train_loader_mc, DEVICE, epochs=EPOCHS_MLP_CIFAR, weight_decay=1e-4)\n",
        "sd_b_mc = model_b_mc.state_dict()\n",
        "loss_b_mc, acc_b_mc = evaluate_model(model_b_mc, test_loader_mc, DEVICE)\n",
        "print(f\"Model B (MLP-CIFAR) - Test Loss: {loss_b_mc:.4f}, Test Accuracy: {acc_b_mc:.2f}%\")\n",
        "\n",
        "# 4. Esecuzione degli allineamenti\n",
        "print(\"\\n--- Executing alignments for MLP on CIFAR10 ---\")\n",
        "permutation_aligner_mc = PermutationAligner(MODEL_ARCH_MLP_CIFAR)\n",
        "aligned_sd_b_perm_mc = permutation_aligner_mc.align(sd_a_mc, sd_b_mc)\n",
        "\n",
        "orthogonal_aligner_mc = OrthogonalAligner(MODEL_ARCH_MLP_CIFAR)\n",
        "aligned_sd_b_orth_mc = orthogonal_aligner_mc.align(sd_a_mc, sd_b_mc)\n",
        "\n",
        "# 5. Esecuzione delle interpolazioni\n",
        "print(\"\\n--- Executing interpolations for MLP on CIFAR10 ---\")\n",
        "alphas_mc_naive, losses_mc_naive, accs_mc_naive = evaluate_interpolation(MODEL_ARCH_MLP_CIFAR, sd_a_mc, sd_b_mc, test_loader_mc, DEVICE)\n",
        "alphas_mc_perm, losses_mc_perm, accs_mc_perm = evaluate_interpolation(MODEL_ARCH_MLP_CIFAR, sd_a_mc, aligned_sd_b_perm_mc, test_loader_mc, DEVICE)\n",
        "alphas_mc_orth, losses_mc_orth, accs_mc_orth = evaluate_interpolation(MODEL_ARCH_MLP_CIFAR, sd_a_mc, aligned_sd_b_orth_mc, test_loader_mc, DEVICE)\n",
        "alphas_mc_slerp, losses_mc_slerp, accs_mc_slerp = slerp_evaluate_interpolation(MODEL_ARCH_MLP_CIFAR, sd_a_mc, aligned_sd_b_perm_mc, test_loader_mc, DEVICE)\n",
        "\n",
        "# 6. Generazione dei grafici\n",
        "print(\"\\n--- Generating graphs ---\")\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
        "\n",
        "ax1.plot(alphas_mc_naive, losses_mc_naive, marker='o', linestyle='--', label='Unaligned (LERP)')\n",
        "ax1.plot(alphas_mc_perm, losses_mc_perm, marker='s', linestyle='-', label='Permutation-Aligned (LERP)')\n",
        "ax1.plot(alphas_mc_orth, losses_mc_orth, marker='x', linestyle=':', label='Orthogonal-Aligned (LERP)')\n",
        "ax1.plot(alphas_mc_slerp, losses_mc_slerp, marker='d', linestyle='-.', label='Permutation-Aligned (SLERP)')\n",
        "ax1.set_title('Test Loss during Interpolation (MLP on CIFAR-10)')\n",
        "ax1.set_xlabel('Interpolation Coefficient (α)')\n",
        "ax1.set_ylabel('Test Loss')\n",
        "ax1.grid(True)\n",
        "ax1.legend()\n",
        "\n",
        "ax2.plot(alphas_mc_naive, accs_mc_naive, marker='o', linestyle='--', label='Unaligned (LERP)')\n",
        "ax2.plot(alphas_mc_perm, accs_mc_perm, marker='s', linestyle='-', label='Permutation-Aligned (LERP)')\n",
        "ax2.plot(alphas_mc_orth, accs_mc_orth, marker='x', linestyle=':', label='Orthogonal-Aligned (LERP)')\n",
        "ax2.plot(alphas_mc_slerp, accs_mc_slerp, marker='d', linestyle='-.', label='Permutation-Aligned (SLERP)')\n",
        "ax2.set_title('Test Accuracy during Interpolation (MLP on CIFAR-10)')\n",
        "ax2.set_xlabel('Interpolation Coefficient (α)')\n",
        "ax2.set_ylabel('Test Accuracy (%)')\n",
        "ax2.grid(True)\n",
        "min_acc = np.min(np.concatenate([accs_mc_naive, accs_mc_orth, accs_mc_perm])) if len(accs_mc_naive) > 0 else 10\n",
        "ax2.set_ylim(bottom=max(0, min_acc - 5), top=60) # Adattiamo l'asse Y\n",
        "ax2.legend()\n",
        "\n",
        "plt.suptitle('Comparison of Alignment Methods for MLP on CIFAR-10', fontsize=16)\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.95])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
